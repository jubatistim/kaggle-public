{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_protein_id</th>\n",
       "      <th>protein_seq</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>peptide_seq</th>\n",
       "      <th>chou_fasman</th>\n",
       "      <th>emini</th>\n",
       "      <th>kolaskar_tongaonkar</th>\n",
       "      <th>parker</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>stability</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2T3T0</td>\n",
       "      <td>MDVLYSLSKTLKDARDKIVEGTLYSNVSDLIQQFNQMIITMNGNEF...</td>\n",
       "      <td>161</td>\n",
       "      <td>165</td>\n",
       "      <td>SASFT</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.703</td>\n",
       "      <td>1.018</td>\n",
       "      <td>2.22</td>\n",
       "      <td>5.810364</td>\n",
       "      <td>0.103275</td>\n",
       "      <td>-0.143829</td>\n",
       "      <td>40.273300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F0V2I4</td>\n",
       "      <td>MTIHKVAINGFGRIGRLLFRNLLSSQGVQVVAVNDVVDIKVLTHLL...</td>\n",
       "      <td>251</td>\n",
       "      <td>255</td>\n",
       "      <td>LCLKI</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.199</td>\n",
       "      <td>-3.86</td>\n",
       "      <td>6.210876</td>\n",
       "      <td>0.065476</td>\n",
       "      <td>-0.036905</td>\n",
       "      <td>24.998512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O75508</td>\n",
       "      <td>MVATCLQVVGFVTSFVGWIGVIVTTSTNDWVVTCGYTIPTCRKLDE...</td>\n",
       "      <td>145</td>\n",
       "      <td>149</td>\n",
       "      <td>AHRET</td>\n",
       "      <td>0.852</td>\n",
       "      <td>3.427</td>\n",
       "      <td>0.960</td>\n",
       "      <td>4.28</td>\n",
       "      <td>8.223938</td>\n",
       "      <td>0.091787</td>\n",
       "      <td>0.879227</td>\n",
       "      <td>27.863333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O84462</td>\n",
       "      <td>MTNSISGYQPTVTTSTSSTTSASGASGSLGASSVSTTANATVTQTA...</td>\n",
       "      <td>152</td>\n",
       "      <td>156</td>\n",
       "      <td>SNYDD</td>\n",
       "      <td>1.410</td>\n",
       "      <td>2.548</td>\n",
       "      <td>0.936</td>\n",
       "      <td>6.32</td>\n",
       "      <td>4.237976</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>-0.521393</td>\n",
       "      <td>30.765373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P00918</td>\n",
       "      <td>MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...</td>\n",
       "      <td>85</td>\n",
       "      <td>89</td>\n",
       "      <td>DGTYR</td>\n",
       "      <td>1.214</td>\n",
       "      <td>1.908</td>\n",
       "      <td>0.937</td>\n",
       "      <td>4.64</td>\n",
       "      <td>6.867493</td>\n",
       "      <td>0.103846</td>\n",
       "      <td>-0.578846</td>\n",
       "      <td>21.684615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_protein_id                                        protein_seq  \\\n",
       "0            A2T3T0  MDVLYSLSKTLKDARDKIVEGTLYSNVSDLIQQFNQMIITMNGNEF...   \n",
       "1            F0V2I4  MTIHKVAINGFGRIGRLLFRNLLSSQGVQVVAVNDVVDIKVLTHLL...   \n",
       "2            O75508  MVATCLQVVGFVTSFVGWIGVIVTTSTNDWVVTCGYTIPTCRKLDE...   \n",
       "3            O84462  MTNSISGYQPTVTTSTSSTTSASGASGSLGASSVSTTANATVTQTA...   \n",
       "4            P00918  MSHHWGYGKHNGPEHWHKDFPIAKGERQSPVDIDTHTAKYDPSLKP...   \n",
       "\n",
       "   start_position  end_position peptide_seq  chou_fasman  emini  \\\n",
       "0             161           165       SASFT        1.016  0.703   \n",
       "1             251           255       LCLKI        0.770  0.179   \n",
       "2             145           149       AHRET        0.852  3.427   \n",
       "3             152           156       SNYDD        1.410  2.548   \n",
       "4              85            89       DGTYR        1.214  1.908   \n",
       "\n",
       "   kolaskar_tongaonkar  parker  isoelectric_point  aromaticity  \\\n",
       "0                1.018    2.22           5.810364     0.103275   \n",
       "1                1.199   -3.86           6.210876     0.065476   \n",
       "2                0.960    4.28           8.223938     0.091787   \n",
       "3                0.936    6.32           4.237976     0.044776   \n",
       "4                0.937    4.64           6.867493     0.103846   \n",
       "\n",
       "   hydrophobicity  stability  target  \n",
       "0       -0.143829  40.273300       1  \n",
       "1       -0.036905  24.998512       1  \n",
       "2        0.879227  27.863333       1  \n",
       "3       -0.521393  30.765373       1  \n",
       "4       -0.578846  21.684615       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('795813_1365687_bundle_archive/input_bcell.csv')\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['parent_protein_id', 'protein_seq', 'start_position', 'end_position',\n",
       "       'peptide_seq', 'chou_fasman', 'emini', 'kolaskar_tongaonkar', 'parker',\n",
       "       'isoelectric_point', 'aromaticity', 'hydrophobicity', 'stability',\n",
       "       'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parent_protein_id      0\n",
       "protein_seq            0\n",
       "start_position         0\n",
       "end_position           0\n",
       "peptide_seq            0\n",
       "chou_fasman            0\n",
       "emini                  0\n",
       "kolaskar_tongaonkar    0\n",
       "parker                 0\n",
       "isoelectric_point      0\n",
       "aromaticity            0\n",
       "hydrophobicity         0\n",
       "stability              0\n",
       "target                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: [1 0]\n"
     ]
    }
   ],
   "source": [
    "for col in dataset.columns:\n",
    "    x = dataset[col].unique()\n",
    "    if len(x) < 20:\n",
    "        print(f\"{col}: {x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove irrelevant features and get input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>chou_fasman</th>\n",
       "      <th>emini</th>\n",
       "      <th>kolaskar_tongaonkar</th>\n",
       "      <th>parker</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>stability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161</td>\n",
       "      <td>165</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.703</td>\n",
       "      <td>1.018</td>\n",
       "      <td>2.22</td>\n",
       "      <td>5.810364</td>\n",
       "      <td>0.103275</td>\n",
       "      <td>-0.143829</td>\n",
       "      <td>40.273300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>255</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1.199</td>\n",
       "      <td>-3.86</td>\n",
       "      <td>6.210876</td>\n",
       "      <td>0.065476</td>\n",
       "      <td>-0.036905</td>\n",
       "      <td>24.998512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145</td>\n",
       "      <td>149</td>\n",
       "      <td>0.852</td>\n",
       "      <td>3.427</td>\n",
       "      <td>0.960</td>\n",
       "      <td>4.28</td>\n",
       "      <td>8.223938</td>\n",
       "      <td>0.091787</td>\n",
       "      <td>0.879227</td>\n",
       "      <td>27.863333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>152</td>\n",
       "      <td>156</td>\n",
       "      <td>1.410</td>\n",
       "      <td>2.548</td>\n",
       "      <td>0.936</td>\n",
       "      <td>6.32</td>\n",
       "      <td>4.237976</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>-0.521393</td>\n",
       "      <td>30.765373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85</td>\n",
       "      <td>89</td>\n",
       "      <td>1.214</td>\n",
       "      <td>1.908</td>\n",
       "      <td>0.937</td>\n",
       "      <td>4.64</td>\n",
       "      <td>6.867493</td>\n",
       "      <td>0.103846</td>\n",
       "      <td>-0.578846</td>\n",
       "      <td>21.684615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_position  end_position  chou_fasman  emini  kolaskar_tongaonkar  \\\n",
       "0             161           165        1.016  0.703                1.018   \n",
       "1             251           255        0.770  0.179                1.199   \n",
       "2             145           149        0.852  3.427                0.960   \n",
       "3             152           156        1.410  2.548                0.936   \n",
       "4              85            89        1.214  1.908                0.937   \n",
       "\n",
       "   parker  isoelectric_point  aromaticity  hydrophobicity  stability  \n",
       "0    2.22           5.810364     0.103275       -0.143829  40.273300  \n",
       "1   -3.86           6.210876     0.065476       -0.036905  24.998512  \n",
       "2    4.28           8.223938     0.091787        0.879227  27.863333  \n",
       "3    6.32           4.237976     0.044776       -0.521393  30.765373  \n",
       "4    4.64           6.867493     0.103846       -0.578846  21.684615  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.drop(columns=['parent_protein_id', 'protein_seq', 'peptide_seq', 'target'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset['target']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3863855 , -0.40451394,  0.17066955, ...,  1.06912809,\n",
       "         0.66463514, -0.20564963],\n",
       "       [-0.13195355, -0.15007612, -1.80099114, ..., -0.39782531,\n",
       "         0.93560006, -1.12130643],\n",
       "       [-0.43161785, -0.44974733, -1.14377091, ...,  0.62331337,\n",
       "         3.25724616, -0.9495729 ],\n",
       "       ...,\n",
       "       [-0.3072289 , -0.29708464, -1.39223222, ..., -0.15555999,\n",
       "        -0.7475483 ,  0.19010766],\n",
       "       [ 3.33962909,  3.34985741,  0.59545824, ..., -1.21820059,\n",
       "        -0.67131514, -0.8518031 ],\n",
       "       [ 3.81456874,  3.824808  , -0.26213401, ..., -1.21820059,\n",
       "        -0.67131514, -0.8518031 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1295/1295 [==============================] - 1s 867us/step - loss: 0.6031 - accuracy: 0.7275\n",
      "Epoch 2/300\n",
      "1295/1295 [==============================] - 1s 855us/step - loss: 0.5854 - accuracy: 0.7280\n",
      "Epoch 3/300\n",
      "1295/1295 [==============================] - 1s 852us/step - loss: 0.5854 - accuracy: 0.7280\n",
      "Epoch 4/300\n",
      "1295/1295 [==============================] - 1s 853us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 5/300\n",
      "1295/1295 [==============================] - 1s 853us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 6/300\n",
      "1295/1295 [==============================] - 1s 861us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 7/300\n",
      "1295/1295 [==============================] - 1s 849us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 8/300\n",
      "1295/1295 [==============================] - 1s 853us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 9/300\n",
      "1295/1295 [==============================] - 1s 892us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 10/300\n",
      "1295/1295 [==============================] - 1s 917us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 11/300\n",
      "1295/1295 [==============================] - 1s 910us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 12/300\n",
      "1295/1295 [==============================] - 1s 905us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 13/300\n",
      "1295/1295 [==============================] - 1s 898us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 14/300\n",
      "1295/1295 [==============================] - 1s 912us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 15/300\n",
      "1295/1295 [==============================] - 1s 912us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 16/300\n",
      "1295/1295 [==============================] - 1s 908us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 17/300\n",
      "1295/1295 [==============================] - 1s 907us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 18/300\n",
      "1295/1295 [==============================] - 1s 906us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 19/300\n",
      "1295/1295 [==============================] - 1s 922us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 20/300\n",
      "1295/1295 [==============================] - 1s 917us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 21/300\n",
      "1295/1295 [==============================] - 1s 915us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 22/300\n",
      "1295/1295 [==============================] - 1s 916us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 23/300\n",
      "1295/1295 [==============================] - 1s 921us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 24/300\n",
      "1295/1295 [==============================] - 1s 915us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 25/300\n",
      "1295/1295 [==============================] - 1s 925us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 26/300\n",
      "1295/1295 [==============================] - 1s 915us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 27/300\n",
      "1295/1295 [==============================] - 1s 908us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 28/300\n",
      "1295/1295 [==============================] - 1s 929us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 29/300\n",
      "1295/1295 [==============================] - 1s 916us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 30/300\n",
      "1295/1295 [==============================] - 1s 917us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 31/300\n",
      "1295/1295 [==============================] - 1s 921us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 32/300\n",
      "1295/1295 [==============================] - 1s 924us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 33/300\n",
      "1295/1295 [==============================] - 1s 920us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 34/300\n",
      "1295/1295 [==============================] - 1s 913us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 35/300\n",
      "1295/1295 [==============================] - 1s 913us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 36/300\n",
      "1295/1295 [==============================] - 1s 931us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 37/300\n",
      "1295/1295 [==============================] - 1s 920us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 38/300\n",
      "1295/1295 [==============================] - 1s 923us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 39/300\n",
      "1295/1295 [==============================] - 1s 928us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 40/300\n",
      "1295/1295 [==============================] - 1s 920us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 41/300\n",
      "1295/1295 [==============================] - 1s 921us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 42/300\n",
      "1295/1295 [==============================] - 1s 913us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 43/300\n",
      "1295/1295 [==============================] - 1s 924us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 44/300\n",
      "1295/1295 [==============================] - 1s 919us/step - loss: 0.5854 - accuracy: 0.7280\n",
      "Epoch 45/300\n",
      "1295/1295 [==============================] - 1s 928us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 46/300\n",
      "1295/1295 [==============================] - 1s 925us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 47/300\n",
      "1295/1295 [==============================] - 1s 919us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 48/300\n",
      "1295/1295 [==============================] - 1s 914us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 49/300\n",
      "1295/1295 [==============================] - 1s 922us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 50/300\n",
      "1295/1295 [==============================] - 1s 922us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 51/300\n",
      "1295/1295 [==============================] - 1s 926us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 52/300\n",
      "1295/1295 [==============================] - 1s 923us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 53/300\n",
      "1295/1295 [==============================] - 1s 930us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 54/300\n",
      "1295/1295 [==============================] - 1s 940us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 55/300\n",
      "1295/1295 [==============================] - 1s 943us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 56/300\n",
      "1295/1295 [==============================] - 1s 925us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 57/300\n",
      "1295/1295 [==============================] - 1s 917us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 58/300\n",
      "1295/1295 [==============================] - 1s 920us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 59/300\n",
      "1295/1295 [==============================] - 1s 915us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 60/300\n",
      "1295/1295 [==============================] - 1s 922us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 61/300\n",
      "1295/1295 [==============================] - 1s 929us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 62/300\n",
      "1295/1295 [==============================] - 1s 924us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 63/300\n",
      "1295/1295 [==============================] - 1s 919us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 64/300\n",
      "1295/1295 [==============================] - 1s 941us/step - loss: 0.5854 - accuracy: 0.7280\n",
      "Epoch 65/300\n",
      "1295/1295 [==============================] - 1s 953us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 66/300\n",
      "1295/1295 [==============================] - 1s 956us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 67/300\n",
      "1295/1295 [==============================] - 1s 927us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 68/300\n",
      "1295/1295 [==============================] - 1s 917us/step - loss: 0.5854 - accuracy: 0.7280\n",
      "Epoch 69/300\n",
      "1295/1295 [==============================] - 1s 915us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 70/300\n",
      "1295/1295 [==============================] - 1s 924us/step - loss: 0.5853 - accuracy: 0.72800s - loss: 0.5\n",
      "Epoch 71/300\n",
      "1295/1295 [==============================] - 1s 942us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 72/300\n",
      "1295/1295 [==============================] - 1s 942us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 73/300\n",
      "1295/1295 [==============================] - 1s 952us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 74/300\n",
      "1295/1295 [==============================] - 1s 949us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 75/300\n",
      "1295/1295 [==============================] - 1s 957us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 76/300\n",
      "1295/1295 [==============================] - 1s 989us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 77/300\n",
      "1295/1295 [==============================] - 1s 961us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 78/300\n",
      "1295/1295 [==============================] - 1s 890us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 79/300\n",
      "1295/1295 [==============================] - 1s 896us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 80/300\n",
      "1295/1295 [==============================] - 1s 916us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 81/300\n",
      "1295/1295 [==============================] - 1s 924us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 82/300\n",
      "1295/1295 [==============================] - 1s 919us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 83/300\n",
      "1295/1295 [==============================] - 1s 913us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 84/300\n",
      "1295/1295 [==============================] - 1s 905us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 85/300\n",
      "1295/1295 [==============================] - 1s 902us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 86/300\n",
      "1295/1295 [==============================] - 1s 963us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 87/300\n",
      "1295/1295 [==============================] - 1s 815us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 88/300\n",
      "1295/1295 [==============================] - 1s 873us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 89/300\n",
      "1295/1295 [==============================] - 1s 891us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 90/300\n",
      "1295/1295 [==============================] - 1s 887us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 91/300\n",
      "1295/1295 [==============================] - 1s 887us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 92/300\n",
      "1295/1295 [==============================] - 1s 970us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 93/300\n",
      "1295/1295 [==============================] - 1s 886us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 94/300\n",
      "1295/1295 [==============================] - 1s 886us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 95/300\n",
      "1295/1295 [==============================] - 1s 889us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 96/300\n",
      "1295/1295 [==============================] - 1s 912us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 97/300\n",
      "1295/1295 [==============================] - 1s 905us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 98/300\n",
      "1295/1295 [==============================] - 1s 895us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 99/300\n",
      "1295/1295 [==============================] - 1s 869us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 100/300\n",
      "1295/1295 [==============================] - 1s 876us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 101/300\n",
      "1295/1295 [==============================] - 1s 876us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 102/300\n",
      "1295/1295 [==============================] - 1s 881us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 103/300\n",
      "1295/1295 [==============================] - 1s 875us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 104/300\n",
      "1295/1295 [==============================] - 1s 872us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 105/300\n",
      "1295/1295 [==============================] - 1s 910us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 106/300\n",
      "1295/1295 [==============================] - 1s 888us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 107/300\n",
      "1295/1295 [==============================] - 1s 906us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 108/300\n",
      "1295/1295 [==============================] - 1s 876us/step - loss: 0.5852 - accuracy: 0.7280\n",
      "Epoch 109/300\n",
      "1295/1295 [==============================] - 1s 907us/step - loss: 0.5854 - accuracy: 0.7280\n",
      "Epoch 110/300\n",
      "1295/1295 [==============================] - 1s 949us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 111/300\n",
      "1295/1295 [==============================] - 1s 816us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 112/300\n",
      "1295/1295 [==============================] - 1s 873us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 113/300\n",
      "1295/1295 [==============================] - 1s 880us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 114/300\n",
      "1295/1295 [==============================] - 1s 898us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 115/300\n",
      "1295/1295 [==============================] - 1s 880us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 116/300\n",
      "1295/1295 [==============================] - 1s 870us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 117/300\n",
      "1295/1295 [==============================] - 1s 868us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 118/300\n",
      "1295/1295 [==============================] - 1s 878us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 119/300\n",
      "1295/1295 [==============================] - 1s 869us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 120/300\n",
      "1295/1295 [==============================] - 1s 875us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 121/300\n",
      "1295/1295 [==============================] - 1s 922us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 122/300\n",
      "1295/1295 [==============================] - 1s 892us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 123/300\n",
      "1295/1295 [==============================] - 1s 883us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 124/300\n",
      "1295/1295 [==============================] - 1s 889us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 125/300\n",
      "1295/1295 [==============================] - 1s 875us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 126/300\n",
      "1295/1295 [==============================] - 1s 884us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 127/300\n",
      "1295/1295 [==============================] - 1s 904us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 128/300\n",
      "1295/1295 [==============================] - 1s 930us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 129/300\n",
      "1295/1295 [==============================] - 1s 944us/step - loss: 0.5854 - accuracy: 0.7280\n",
      "Epoch 130/300\n",
      "1295/1295 [==============================] - 1s 940us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 131/300\n",
      "1295/1295 [==============================] - 1s 926us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 132/300\n",
      "1295/1295 [==============================] - 1s 928us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 133/300\n",
      "1295/1295 [==============================] - 1s 916us/step - loss: 0.5852 - accuracy: 0.7280\n",
      "Epoch 134/300\n",
      "1295/1295 [==============================] - 1s 925us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 135/300\n",
      "1295/1295 [==============================] - 1s 923us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 136/300\n",
      "1295/1295 [==============================] - 1s 941us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 137/300\n",
      "1295/1295 [==============================] - 1s 943us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 138/300\n",
      "1295/1295 [==============================] - 1s 961us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 139/300\n",
      "1295/1295 [==============================] - 1s 919us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 140/300\n",
      "1295/1295 [==============================] - 1s 931us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 141/300\n",
      "1295/1295 [==============================] - 1s 968us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 142/300\n",
      "1295/1295 [==============================] - 1s 884us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 143/300\n",
      "1295/1295 [==============================] - 1s 884us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 144/300\n",
      "1295/1295 [==============================] - 1s 880us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 145/300\n",
      "1295/1295 [==============================] - 1s 913us/step - loss: 0.5852 - accuracy: 0.7280\n",
      "Epoch 146/300\n",
      "1295/1295 [==============================] - 1s 902us/step - loss: 0.5854 - accuracy: 0.7280\n",
      "Epoch 147/300\n",
      "1295/1295 [==============================] - 1s 879us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 148/300\n",
      "1295/1295 [==============================] - 1s 880us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 149/300\n",
      "1295/1295 [==============================] - 1s 878us/step - loss: 0.5852 - accuracy: 0.7280\n",
      "Epoch 150/300\n",
      "1295/1295 [==============================] - 1s 931us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 151/300\n",
      "1295/1295 [==============================] - 1s 884us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 152/300\n",
      "1295/1295 [==============================] - 1s 882us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 153/300\n",
      "1295/1295 [==============================] - 1s 887us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 154/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1295/1295 [==============================] - 1s 863us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 155/300\n",
      "1295/1295 [==============================] - 1s 844us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 156/300\n",
      "1295/1295 [==============================] - 1s 843us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 157/300\n",
      "1295/1295 [==============================] - 1s 856us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 158/300\n",
      "1295/1295 [==============================] - 1s 853us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 159/300\n",
      "1295/1295 [==============================] - 1s 853us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 160/300\n",
      "1295/1295 [==============================] - 1s 864us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 161/300\n",
      "1295/1295 [==============================] - 1s 887us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 162/300\n",
      "1295/1295 [==============================] - 1s 902us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 163/300\n",
      "1295/1295 [==============================] - 1s 899us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 164/300\n",
      "1295/1295 [==============================] - 1s 899us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 165/300\n",
      "1295/1295 [==============================] - 1s 890us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 166/300\n",
      "1295/1295 [==============================] - 1s 900us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 167/300\n",
      "1295/1295 [==============================] - 1s 897us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 168/300\n",
      "1295/1295 [==============================] - 1s 893us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 169/300\n",
      "1295/1295 [==============================] - 1s 894us/step - loss: 0.5853 - accuracy: 0.72800s - loss: 0.5854 - accuracy: 0.\n",
      "Epoch 170/300\n",
      "1295/1295 [==============================] - 1s 895us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 171/300\n",
      "1295/1295 [==============================] - 1s 893us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 172/300\n",
      "1295/1295 [==============================] - 1s 890us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 173/300\n",
      "1295/1295 [==============================] - 1s 896us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 174/300\n",
      "1295/1295 [==============================] - 1s 905us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 175/300\n",
      "1295/1295 [==============================] - 1s 905us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 176/300\n",
      "1295/1295 [==============================] - 1s 896us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 177/300\n",
      "1295/1295 [==============================] - 1s 896us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 178/300\n",
      "1295/1295 [==============================] - 1s 898us/step - loss: 0.5852 - accuracy: 0.7280\n",
      "Epoch 179/300\n",
      "1295/1295 [==============================] - 1s 907us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 180/300\n",
      "1295/1295 [==============================] - 1s 893us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 181/300\n",
      "1295/1295 [==============================] - 1s 902us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 182/300\n",
      "1295/1295 [==============================] - 1s 890us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 183/300\n",
      "1295/1295 [==============================] - 1s 900us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 184/300\n",
      "1295/1295 [==============================] - 1s 892us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 185/300\n",
      "1295/1295 [==============================] - 1s 899us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 186/300\n",
      "1295/1295 [==============================] - 1s 900us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 187/300\n",
      "1295/1295 [==============================] - 1s 900us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 188/300\n",
      "1295/1295 [==============================] - 1s 894us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 189/300\n",
      "1295/1295 [==============================] - 1s 890us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 190/300\n",
      "1295/1295 [==============================] - 1s 910us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 191/300\n",
      "1295/1295 [==============================] - 1s 896us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 192/300\n",
      "1295/1295 [==============================] - 1s 902us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 193/300\n",
      "1295/1295 [==============================] - 1s 902us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 194/300\n",
      "1295/1295 [==============================] - 1s 899us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 195/300\n",
      "1295/1295 [==============================] - 1s 880us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 196/300\n",
      "1295/1295 [==============================] - 1s 866us/step - loss: 0.5853 - accuracy: 0.7280\n",
      "Epoch 197/300\n",
      "1295/1295 [==============================] - 1s 842us/step - loss: 0.5852 - accuracy: 0.7280\n",
      "Epoch 198/300\n",
      "1295/1295 [==============================] - 1s 822us/step - loss: 0.5852 - accuracy: 0.7280\n",
      "Epoch 199/300\n",
      "1295/1295 [==============================] - 1s 808us/step - loss: 0.5852 - accuracy: 0.7280\n",
      "Epoch 200/300\n",
      "1295/1295 [==============================] - 1s 831us/step - loss: 0.5852 - accuracy: 0.7280\n",
      "Epoch 201/300\n",
      "1295/1295 [==============================] - 1s 857us/step - loss: 0.5852 - accuracy: 0.7280\n",
      "Epoch 202/300\n",
      "1295/1295 [==============================] - 1s 857us/step - loss: 0.5852 - accuracy: 0.7280\n",
      "Epoch 203/300\n",
      "1295/1295 [==============================] - 1s 849us/step - loss: 0.5851 - accuracy: 0.7280\n",
      "Epoch 204/300\n",
      "1295/1295 [==============================] - 1s 842us/step - loss: 0.5852 - accuracy: 0.7280\n",
      "Epoch 205/300\n",
      "1295/1295 [==============================] - 1s 857us/step - loss: 0.5852 - accuracy: 0.7280\n",
      "Epoch 206/300\n",
      "1295/1295 [==============================] - 1s 852us/step - loss: 0.5851 - accuracy: 0.7280\n",
      "Epoch 207/300\n",
      "1295/1295 [==============================] - 1s 854us/step - loss: 0.5851 - accuracy: 0.7280\n",
      "Epoch 208/300\n",
      "1295/1295 [==============================] - 1s 859us/step - loss: 0.5851 - accuracy: 0.7280\n",
      "Epoch 209/300\n",
      "1295/1295 [==============================] - 1s 864us/step - loss: 0.5850 - accuracy: 0.7280\n",
      "Epoch 210/300\n",
      "1295/1295 [==============================] - 1s 899us/step - loss: 0.5850 - accuracy: 0.7280\n",
      "Epoch 211/300\n",
      "1295/1295 [==============================] - 1s 901us/step - loss: 0.5849 - accuracy: 0.7280\n",
      "Epoch 212/300\n",
      "1295/1295 [==============================] - 1s 898us/step - loss: 0.5849 - accuracy: 0.7280\n",
      "Epoch 213/300\n",
      "1295/1295 [==============================] - 1s 920us/step - loss: 0.5848 - accuracy: 0.7280\n",
      "Epoch 214/300\n",
      "1295/1295 [==============================] - 1s 901us/step - loss: 0.5846 - accuracy: 0.7280\n",
      "Epoch 215/300\n",
      "1295/1295 [==============================] - 1s 901us/step - loss: 0.5843 - accuracy: 0.7280\n",
      "Epoch 216/300\n",
      "1295/1295 [==============================] - 1s 898us/step - loss: 0.5839 - accuracy: 0.7280\n",
      "Epoch 217/300\n",
      "1295/1295 [==============================] - 1s 900us/step - loss: 0.5833 - accuracy: 0.7280\n",
      "Epoch 218/300\n",
      "1295/1295 [==============================] - 1s 890us/step - loss: 0.5822 - accuracy: 0.7280\n",
      "Epoch 219/300\n",
      "1295/1295 [==============================] - 1s 896us/step - loss: 0.5797 - accuracy: 0.7280\n",
      "Epoch 220/300\n",
      "1295/1295 [==============================] - 1s 903us/step - loss: 0.5744 - accuracy: 0.7280\n",
      "Epoch 221/300\n",
      "1295/1295 [==============================] - 1s 852us/step - loss: 0.5653 - accuracy: 0.7280\n",
      "Epoch 222/300\n",
      "1295/1295 [==============================] - 1s 856us/step - loss: 0.5572 - accuracy: 0.7284\n",
      "Epoch 223/300\n",
      "1295/1295 [==============================] - 1s 851us/step - loss: 0.5545 - accuracy: 0.7289\n",
      "Epoch 224/300\n",
      "1295/1295 [==============================] - 1s 852us/step - loss: 0.5534 - accuracy: 0.7286\n",
      "Epoch 225/300\n",
      "1295/1295 [==============================] - 1s 852us/step - loss: 0.5522 - accuracy: 0.7302\n",
      "Epoch 226/300\n",
      "1295/1295 [==============================] - 1s 852us/step - loss: 0.5513 - accuracy: 0.7295\n",
      "Epoch 227/300\n",
      "1295/1295 [==============================] - 1s 857us/step - loss: 0.5504 - accuracy: 0.7288\n",
      "Epoch 228/300\n",
      "1295/1295 [==============================] - 1s 849us/step - loss: 0.5493 - accuracy: 0.7291\n",
      "Epoch 229/300\n",
      "1295/1295 [==============================] - 1s 859us/step - loss: 0.5480 - accuracy: 0.7291\n",
      "Epoch 230/300\n",
      "1295/1295 [==============================] - 1s 846us/step - loss: 0.5467 - accuracy: 0.7297\n",
      "Epoch 231/300\n",
      "1295/1295 [==============================] - 1s 848us/step - loss: 0.5457 - accuracy: 0.7305\n",
      "Epoch 232/300\n",
      "1295/1295 [==============================] - 1s 856us/step - loss: 0.5441 - accuracy: 0.7307\n",
      "Epoch 233/300\n",
      "1295/1295 [==============================] - 1s 851us/step - loss: 0.5428 - accuracy: 0.7319\n",
      "Epoch 234/300\n",
      "1295/1295 [==============================] - 1s 851us/step - loss: 0.5415 - accuracy: 0.7311\n",
      "Epoch 235/300\n",
      "1295/1295 [==============================] - 1s 834us/step - loss: 0.5407 - accuracy: 0.7321\n",
      "Epoch 236/300\n",
      "1295/1295 [==============================] - 1s 866us/step - loss: 0.5389 - accuracy: 0.7325\n",
      "Epoch 237/300\n",
      "1295/1295 [==============================] - 1s 893us/step - loss: 0.5374 - accuracy: 0.7335\n",
      "Epoch 238/300\n",
      "1295/1295 [==============================] - 1s 889us/step - loss: 0.5354 - accuracy: 0.7350\n",
      "Epoch 239/300\n",
      "1295/1295 [==============================] - 1s 901us/step - loss: 0.5336 - accuracy: 0.7350\n",
      "Epoch 240/300\n",
      "1295/1295 [==============================] - 1s 901us/step - loss: 0.5314 - accuracy: 0.7373\n",
      "Epoch 241/300\n",
      "1295/1295 [==============================] - 1s 897us/step - loss: 0.5300 - accuracy: 0.7370\n",
      "Epoch 242/300\n",
      "1295/1295 [==============================] - 1s 943us/step - loss: 0.5288 - accuracy: 0.7397\n",
      "Epoch 243/300\n",
      "1295/1295 [==============================] - 1s 943us/step - loss: 0.5274 - accuracy: 0.7386\n",
      "Epoch 244/300\n",
      "1295/1295 [==============================] - 1s 844us/step - loss: 0.5255 - accuracy: 0.7413\n",
      "Epoch 245/300\n",
      "1295/1295 [==============================] - 1s 851us/step - loss: 0.5249 - accuracy: 0.7441\n",
      "Epoch 246/300\n",
      "1295/1295 [==============================] - 1s 855us/step - loss: 0.5224 - accuracy: 0.7472\n",
      "Epoch 247/300\n",
      "1295/1295 [==============================] - 1s 849us/step - loss: 0.5200 - accuracy: 0.7470\n",
      "Epoch 248/300\n",
      "1295/1295 [==============================] - 1s 851us/step - loss: 0.5164 - accuracy: 0.7519\n",
      "Epoch 249/300\n",
      "1295/1295 [==============================] - 1s 850us/step - loss: 0.5139 - accuracy: 0.7550\n",
      "Epoch 250/300\n",
      "1295/1295 [==============================] - 1s 853us/step - loss: 0.5101 - accuracy: 0.7580\n",
      "Epoch 251/300\n",
      "1295/1295 [==============================] - 1s 852us/step - loss: 0.5063 - accuracy: 0.7602\n",
      "Epoch 252/300\n",
      "1295/1295 [==============================] - 1s 851us/step - loss: 0.5039 - accuracy: 0.7620\n",
      "Epoch 253/300\n",
      "1295/1295 [==============================] - 1s 850us/step - loss: 0.4997 - accuracy: 0.7641\n",
      "Epoch 254/300\n",
      "1295/1295 [==============================] - 1s 875us/step - loss: 0.4970 - accuracy: 0.7681\n",
      "Epoch 255/300\n",
      "1295/1295 [==============================] - 1s 895us/step - loss: 0.4946 - accuracy: 0.7690\n",
      "Epoch 256/300\n",
      "1295/1295 [==============================] - 1s 897us/step - loss: 0.4930 - accuracy: 0.7685\n",
      "Epoch 257/300\n",
      "1295/1295 [==============================] - 1s 902us/step - loss: 0.4897 - accuracy: 0.7696\n",
      "Epoch 258/300\n",
      "1295/1295 [==============================] - 1s 905us/step - loss: 0.4862 - accuracy: 0.7745\n",
      "Epoch 259/300\n",
      "1295/1295 [==============================] - 1s 994us/step - loss: 0.4852 - accuracy: 0.7728\n",
      "Epoch 260/300\n",
      "1295/1295 [==============================] - 1s 929us/step - loss: 0.4835 - accuracy: 0.7718\n",
      "Epoch 261/300\n",
      "1295/1295 [==============================] - 1s 870us/step - loss: 0.4802 - accuracy: 0.7749\n",
      "Epoch 262/300\n",
      "1295/1295 [==============================] - 1s 870us/step - loss: 0.4786 - accuracy: 0.7754\n",
      "Epoch 263/300\n",
      "1295/1295 [==============================] - 1s 905us/step - loss: 0.4740 - accuracy: 0.7765\n",
      "Epoch 264/300\n",
      "1295/1295 [==============================] - 1s 924us/step - loss: 0.4741 - accuracy: 0.7758\n",
      "Epoch 265/300\n",
      "1295/1295 [==============================] - 1s 952us/step - loss: 0.4722 - accuracy: 0.7776\n",
      "Epoch 266/300\n",
      "1295/1295 [==============================] - 1s 935us/step - loss: 0.4684 - accuracy: 0.7819\n",
      "Epoch 267/300\n",
      "1295/1295 [==============================] - 1s 915us/step - loss: 0.4666 - accuracy: 0.7816\n",
      "Epoch 268/300\n",
      "1295/1295 [==============================] - 1s 948us/step - loss: 0.4660 - accuracy: 0.7793\n",
      "Epoch 269/300\n",
      "1295/1295 [==============================] - 1s 917us/step - loss: 0.4632 - accuracy: 0.7819\n",
      "Epoch 270/300\n",
      "1295/1295 [==============================] - 1s 926us/step - loss: 0.4629 - accuracy: 0.7813\n",
      "Epoch 271/300\n",
      "1295/1295 [==============================] - 1s 914us/step - loss: 0.4615 - accuracy: 0.7832\n",
      "Epoch 272/300\n",
      "1295/1295 [==============================] - 1s 921us/step - loss: 0.4573 - accuracy: 0.7861\n",
      "Epoch 273/300\n",
      "1295/1295 [==============================] - 1s 943us/step - loss: 0.4571 - accuracy: 0.7858\n",
      "Epoch 274/300\n",
      "1295/1295 [==============================] - 1s 947us/step - loss: 0.4561 - accuracy: 0.7855\n",
      "Epoch 275/300\n",
      "1295/1295 [==============================] - 1s 981us/step - loss: 0.4568 - accuracy: 0.7865\n",
      "Epoch 276/300\n",
      "1295/1295 [==============================] - 1s 948us/step - loss: 0.4548 - accuracy: 0.7844\n",
      "Epoch 277/300\n",
      "1295/1295 [==============================] - 1s 906us/step - loss: 0.4536 - accuracy: 0.7851\n",
      "Epoch 278/300\n",
      "1295/1295 [==============================] - 1s 868us/step - loss: 0.4507 - accuracy: 0.7875\n",
      "Epoch 279/300\n",
      "1295/1295 [==============================] - 1s 873us/step - loss: 0.4508 - accuracy: 0.7864\n",
      "Epoch 280/300\n",
      "1295/1295 [==============================] - 1s 875us/step - loss: 0.4487 - accuracy: 0.7879\n",
      "Epoch 281/300\n",
      "1295/1295 [==============================] - 1s 882us/step - loss: 0.4486 - accuracy: 0.7857\n",
      "Epoch 282/300\n",
      "1295/1295 [==============================] - 1s 883us/step - loss: 0.4469 - accuracy: 0.7879\n",
      "Epoch 283/300\n",
      "1295/1295 [==============================] - 1s 931us/step - loss: 0.4463 - accuracy: 0.7913\n",
      "Epoch 284/300\n",
      "1295/1295 [==============================] - 1s 960us/step - loss: 0.4443 - accuracy: 0.7888\n",
      "Epoch 285/300\n",
      "1295/1295 [==============================] - 1s 958us/step - loss: 0.4434 - accuracy: 0.7919\n",
      "Epoch 286/300\n",
      "1295/1295 [==============================] - 1s 892us/step - loss: 0.4414 - accuracy: 0.7899\n",
      "Epoch 287/300\n",
      "1295/1295 [==============================] - 1s 873us/step - loss: 0.4422 - accuracy: 0.7927\n",
      "Epoch 288/300\n",
      "1295/1295 [==============================] - 1s 901us/step - loss: 0.4411 - accuracy: 0.7907\n",
      "Epoch 289/300\n",
      "1295/1295 [==============================] - 1s 886us/step - loss: 0.4380 - accuracy: 0.7964\n",
      "Epoch 290/300\n",
      "1295/1295 [==============================] - 1s 924us/step - loss: 0.4381 - accuracy: 0.7941\n",
      "Epoch 291/300\n",
      "1295/1295 [==============================] - 1s 925us/step - loss: 0.4356 - accuracy: 0.7966\n",
      "Epoch 292/300\n",
      "1295/1295 [==============================] - 1s 939us/step - loss: 0.4372 - accuracy: 0.7939\n",
      "Epoch 293/300\n",
      "1295/1295 [==============================] - 1s 965us/step - loss: 0.4350 - accuracy: 0.7925\n",
      "Epoch 294/300\n",
      "1295/1295 [==============================] - 1s 963us/step - loss: 0.4343 - accuracy: 0.7963\n",
      "Epoch 295/300\n",
      "1295/1295 [==============================] - 1s 989us/step - loss: 0.4326 - accuracy: 0.7980\n",
      "Epoch 296/300\n",
      "1295/1295 [==============================] - 1s 985us/step - loss: 0.4324 - accuracy: 0.7985\n",
      "Epoch 297/300\n",
      "1295/1295 [==============================] - 1s 953us/step - loss: 0.4301 - accuracy: 0.7976\n",
      "Epoch 298/300\n",
      "1295/1295 [==============================] - 1s 935us/step - loss: 0.4304 - accuracy: 0.7990\n",
      "Epoch 299/300\n",
      "1295/1295 [==============================] - 1s 953us/step - loss: 0.4288 - accuracy: 0.8000\n",
      "Epoch 300/300\n",
      "1295/1295 [==============================] - 1s 891us/step - loss: 0.4273 - accuracy: 0.8025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bbf0275948>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'relu', input_dim = 10))\n",
    "classifier.add(Dense(units = 50, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 30, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 20, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'SGD', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "classifier.save('test-abc-v01.h5')\n",
    "\n",
    "# Save a dictionary into a pickle file.\n",
    "import pickle\n",
    "pickle.dump( sc, open( \"test-abc-v01.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict over test set and check confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[976,  83],\n",
       "       [196, 184]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "sn.heatmap(cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get final ANN accuracy over test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION ACCURACY 0.8061153578874218\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('VALIDATION ACCURACY', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76095154094924"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get SARS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_protein_id</th>\n",
       "      <th>protein_seq</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>peptide_seq</th>\n",
       "      <th>chou_fasman</th>\n",
       "      <th>emini</th>\n",
       "      <th>kolaskar_tongaonkar</th>\n",
       "      <th>parker</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>stability</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>MFIFLLFLTLTSGSDLD</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-2.159</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>MFIFLLFLTLTSGSD</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.047</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-2.500</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>FIFLLFLTL</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.042</td>\n",
       "      <td>1.148</td>\n",
       "      <td>-7.467</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>LFLTLTSGSDLDRCT</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.230</td>\n",
       "      <td>1.049</td>\n",
       "      <td>0.927</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAU93319</td>\n",
       "      <td>MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>TLTSGSDLDRCTTFDDV</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1.015</td>\n",
       "      <td>3.165</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_protein_id                                        protein_seq  \\\n",
       "0          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "1          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "2          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "3          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "4          AAU93319  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...   \n",
       "\n",
       "   start_position  end_position        peptide_seq  chou_fasman  emini  \\\n",
       "0               1            17  MFIFLLFLTLTSGSDLD        0.887  0.040   \n",
       "1               1            15    MFIFLLFLTLTSGSD        0.869  0.047   \n",
       "2               2            10          FIFLLFLTL        0.621  0.042   \n",
       "3               6            20    LFLTLTSGSDLDRCT        1.021  0.230   \n",
       "4               9            25  TLTSGSDLDRCTTFDDV        1.089  0.627   \n",
       "\n",
       "   kolaskar_tongaonkar  parker  isoelectric_point  aromaticity  \\\n",
       "0                1.056  -2.159           5.569763     0.116335   \n",
       "1                1.056  -2.500           5.569763     0.116335   \n",
       "2                1.148  -7.467           5.569763     0.116335   \n",
       "3                1.049   0.927           5.569763     0.116335   \n",
       "4                1.015   3.165           5.569763     0.116335   \n",
       "\n",
       "   hydrophobicity  stability  target  \n",
       "0       -0.061116  33.205116       0  \n",
       "1       -0.061116  33.205116       0  \n",
       "2       -0.061116  33.205116       0  \n",
       "3       -0.061116  33.205116       0  \n",
       "4       -0.061116  33.205116       0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sars = pd.read_csv('795813_1365687_bundle_archive/input_sars.csv')\n",
    "\n",
    "sars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['parent_protein_id', 'protein_seq', 'start_position', 'end_position',\n",
       "       'peptide_seq', 'chou_fasman', 'emini', 'kolaskar_tongaonkar', 'parker',\n",
       "       'isoelectric_point', 'aromaticity', 'hydrophobicity', 'stability',\n",
       "       'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sars.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parent_protein_id      0\n",
       "protein_seq            0\n",
       "start_position         0\n",
       "end_position           0\n",
       "peptide_seq            0\n",
       "chou_fasman            0\n",
       "emini                  0\n",
       "kolaskar_tongaonkar    0\n",
       "parker                 0\n",
       "isoelectric_point      0\n",
       "aromaticity            0\n",
       "hydrophobicity         0\n",
       "stability              0\n",
       "target                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sars.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>chou_fasman</th>\n",
       "      <th>emini</th>\n",
       "      <th>kolaskar_tongaonkar</th>\n",
       "      <th>parker</th>\n",
       "      <th>isoelectric_point</th>\n",
       "      <th>aromaticity</th>\n",
       "      <th>hydrophobicity</th>\n",
       "      <th>stability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-2.159</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.047</td>\n",
       "      <td>1.056</td>\n",
       "      <td>-2.500</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.042</td>\n",
       "      <td>1.148</td>\n",
       "      <td>-7.467</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.230</td>\n",
       "      <td>1.049</td>\n",
       "      <td>0.927</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>1.089</td>\n",
       "      <td>0.627</td>\n",
       "      <td>1.015</td>\n",
       "      <td>3.165</td>\n",
       "      <td>5.569763</td>\n",
       "      <td>0.116335</td>\n",
       "      <td>-0.061116</td>\n",
       "      <td>33.205116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_position  end_position  chou_fasman  emini  kolaskar_tongaonkar  \\\n",
       "0               1            17        0.887  0.040                1.056   \n",
       "1               1            15        0.869  0.047                1.056   \n",
       "2               2            10        0.621  0.042                1.148   \n",
       "3               6            20        1.021  0.230                1.049   \n",
       "4               9            25        1.089  0.627                1.015   \n",
       "\n",
       "   parker  isoelectric_point  aromaticity  hydrophobicity  stability  \n",
       "0  -2.159           5.569763     0.116335       -0.061116  33.205116  \n",
       "1  -2.500           5.569763     0.116335       -0.061116  33.205116  \n",
       "2  -7.467           5.569763     0.116335       -0.061116  33.205116  \n",
       "3   0.927           5.569763     0.116335       -0.061116  33.205116  \n",
       "4   3.165           5.569763     0.116335       -0.061116  33.205116  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sars = sars.drop(columns=['parent_protein_id', 'protein_seq', 'peptide_seq', 'target'])\n",
    "X_sars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sars = sars['target']\n",
    "y_sars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.83870898, -0.8229228 , -0.86325008, ...,  1.57599021,\n",
       "         0.87424551, -0.6293564 ],\n",
       "       [-0.83870898, -0.82857697, -1.00751794, ...,  1.57599021,\n",
       "         0.87424551, -0.6293564 ],\n",
       "       [-0.83588195, -0.8427124 , -2.99520839, ...,  1.57599021,\n",
       "         0.87424551, -0.6293564 ],\n",
       "       ...,\n",
       "       [ 2.65266282,  2.67701074,  0.21074396, ...,  1.57599021,\n",
       "         0.87424551, -0.6293564 ],\n",
       "       [ 2.65266282,  2.6628753 ,  0.45119039, ...,  1.57599021,\n",
       "         0.87424551, -0.6293564 ],\n",
       "       [ 2.66679793,  2.67701074,  0.26684812, ...,  1.57599021,\n",
       "         0.87424551, -0.6293564 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sars = sc.transform(X_sars)\n",
    "\n",
    "X_sars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[289,  91],\n",
       "       [ 92,  48]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "\n",
    "y_sars_pred = classifier.predict(X_sars)\n",
    "y_sars_pred = (y_sars_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_sars, y_sars_pred)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION ACCURACY 0.6480769230769231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('VALIDATION ACCURACY', accuracy_score(y_sars, y_sars_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5519269623671142"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_sars_pred, y_sars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv37",
   "language": "python",
   "name": "venv37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
